colnames(IncomeFamilyCor)[2] <- "Income and Family Income Correlation"
#cor between times charged and income
IncomeTimesChargedCor <- ddply(nlsy_clean, "SEX", function(x) cor(x$Income_2012, x$Times_Charged_Illegal, use = "complete.obs"))
colnames(IncomeTimesChargedCor)[2] <- "Income and Times Charged Correlation"
#categorical------------
#median income by pov/sex
IncomePovertySex <- aggregate(Income_2012 ~ POVSTATUS78 + SEX, median, data=nlsy_clean)
colnames(IncomePovertySex)[1] <- "Poverty Status 1978"
#drug usage and income
IncomeCokeSex <- aggregate(Income_2012 ~ Coke_Use + SEX, median, data=nlsy_clean)
colnames(IncomeCokeSex)[1] <- "Number of Times Used Coke"
IncomeCrackSex <- aggregate(Income_2012 ~ Crack_Use + SEX, median, data=nlsy_clean)
colnames(IncomeCrackSex)[1] <- "Number of Times Used Crack"
#median income by job/sex
IncomeJobSex <- aggregate(Income_2012 ~ Current_Job_Class12 + SEX, median, data=nlsy_clean)
colnames(IncomeJobSex)[1] <- "Current Job Class 2012"
cleanedIncome <- subset(nlsy_clean, Income_2012 > 0 & Income_2012 < 200000, select = c(Income_2012))
#
source('~/.active-rstudio-document', echo=TRUE)
qplot(subset(nlsy_clean, Income_2012 > 0 & Income_2012 < 200000, select = c(Income_2012)))
qplot(cleanedIncome)
cleanedIncome <- subset(nlsy_clean, Income_2012 > 0 & Income_2012 < 200000, select = c(Income_2012))
qplot(cleanedIncome)
count(nlsy_cleanIncome_2012)
count(nlsy_clean$Income_2012)
count(cleanedIncome)
cleanedIncome <- subset(nlsy_clean, Income_2012 > 0 & Income_2012 < 200000, select = c(Income_2012))
count(nlsy_clean$Income_2012)
count(cleanedIncome)
qplot(cleanedIncome)
ggplot(cleanedIncome, aes(x=Income_2012)) + geom_bar()
qplot(nlsy_clean$Income_2012)
qplot(nlsy_clean$Income_2012) + ggtitle("test")
ggplot(cleanedIncome, aes(x=Income_2012)) + geom_bar() + ggtitle("Income Variable without Outliers")
ggplot(subset(nlsy_clean, Income_2012 > 0 & Income_2012 < 200000, select = c(Income_2012)), aes(x=Income_2012)) + geom_bar() + ggtitle("Income Variable without Outliers")
#Create subset of income variable with values >0 and <200000 and plot
ggplot(subset(nlsy_clean, Income_2012 > 0 & Income_2012 < 200000, select = c(Income_2012)), aes(x=Income_2012)) + geom_bar() + ggtitle("Income Variable without Outliers")
final_plot <- plot(lm_final)
base_final_ANOVA
base_final_ANOVA$coef
base_final_ANOVA$pvalue
base_final_ANOVA$pvalue$"PR(>Chi)"
base_final_ANOVA$pvalue$"Pr(>Chi)"
base_final_ANOVA$pvalue$"Pr(>Chi)"[2]
base_final_ANOVA$"Pr(>Chi)"[2]
source('~/.active-rstudio-document', echo=TRUE)
ddply(nlsy_clean, "SEX", function(x) cor(x$Income_2012, x$Family_NET_WORTH_08, use = "complete.obs"))
str(JOBS_Ever_NUM)
str(nlsy_clean$JOBS_Ever_NUM)
unique(nlsy_clean$JOBS_Ever_NUM)
ddply(nlsy_clean, "SEX", function(x) cor(x$Income_2012, x$JOBS_Ever_NUM, use = "complete.obs"))
survey <- read.table("http://www.andrew.cmu.edu/user/achoulde/94842/data/survey_data.csv", header=TRUE, sep=",")
View(survey)
View(survey)
#create vector of MISM students
students_MISM <- survey[survey$Program == "MISM", "Program"]
#create vector of HCPM students
students_HCPM <- survey[survey$Program == "HCPM", "Program"]
#sum length of vectors for total MISM and HCPM students
total_MISM_HCPM <- length(students_MISM) + length(students_HCPM)
str(students_MISM)
head(students_MISM)
students_MISM
#create vector of MISM students
students_MISM <- survey[survey$Program == "MISM"]
#create vector of HCPM students
students_HCPM <- survey[survey$Program == "HCPM", "Program"]
#sum length of vectors for total MISM and HCPM students
total_MISM_HCPM <- length(students_MISM) + length(students_HCPM)
library(foreign)
library(foreign)
#library for other file formats
library(foreign)
#import data
teachingRatings <- read.dta("TeachingRatings.dta")
pwd
pwd()
#library for other file formats
library(foreign)
#import data
teachingRatings <- read.dta("C:\Users\Jackson\Dropbox\Grad School Work\Econometrics 1\Assignment 2\TeachingRatings.dta")
#library for other file formats
library(foreign)
#import data
teachingRatings <- read.dta("C:\\Users\Jackson\\Dropbox\\Grad School Work\\Econometrics 1\\Assignment 2\\TeachingRatings.dta")
#library for other file formats
library(foreign)
#import data
teachingRatings <- read.dta("C:\\Users\\Jackson\\Dropbox\\Grad School Work\\Econometrics 1\\Assignment 2\\TeachingRatings.dta")
str(teachingRatings)
beautyEvalPlot <- ggplot(data=teachingRatings, aes(x=beauty, y=course_eval))
library(ggplot2)
beautyEvalPlot <- ggplot(data=teachingRatings, aes(x=beauty, y=course_eval))
beautyEvalPlot
beautyEvalPlot <- ggplot(data=teachingRatings, aes(x=beauty, y=course_eval))
beautyEvalPlot
beautyEvalPlot <- ggplot(data=teachingRatings, aes(x=beauty, y=course_eval))+geom_boxplot()
beautyEvalPlot
beautyEvalPlot <- ggplot(data=teachingRatings, aes(x=beauty, y=course_eval))+geom_dotplot()
beautyEvalPlot
beautyEvalPlot <- qplot(beauty, course_eval, data=teachingRatings)
beautyEvalPlot
beautyPlot <-qplot(beauty, data=teachingRatings)
beautyPlot
beautyEvalPlot <- qplot(beauty, course_eval, data=teachingRatings)
beautyEvalPlot
cor(teachingRatings$beauty, teachingRatings$course_eval)
table(teachingRatings$beauty, teachingRatings$course_eval)
cor(teachingRatings$beauty, teachingRatings$course_eval)
course_evalBeautyReg <- lm(course_eval, beauty, data=teachingRatings)
course_evalBeautyReg <- lm(course_eval ~ beauty, data=teachingRatings)
summary(course_evalBeautyReg)
library(foreign)
collegeDistance <- read.dta("C:\\Users\\Jackson\\Dropbox\\Grad School Work\\Econometrics 1\\Recitation3\\CollegeDistance.dta")
str(collegeDistance)
eduDistlm <- lm(ed ~ dist, data=collegeDistance)
summary(eduDistlm)
summary(collegeDistance$dist)
confint(eduDistlm)
confint(eduDistlm, level = .95)
confint(eduDistlm, level = 0.95)
confint(eduDistlm, level = 0.90)
confint(eduDistlm, level = 0.95)
summary(eduDistlm)
plot(eduDistlm)
plot(eduDistlm)
library(foreign)
#Recitation 3
collegeDistance <- read.dta("C:\\Users\\Jackson\\Dropbox\\Grad School Work\\Econometrics 1\\Recitation3\\CollegeDistance.dta")
str(collegeDistance)
eduDistlm <- lm(ed ~ dist, data=collegeDistance)
summary(eduDistlm)
confint(eduDistlm, level = 0.95)
summary(collegeDistance$dist)
plot(eduDistlm)
library(ggplot2)
#library for other file formats
library(foreign)
#import data
teachingRatings <- read.dta("C:\\Users\\Jackson\\Dropbox\\Grad School Work\\Econometrics 1\\Assignment 2\\TeachingRatings.dta")
#check out data
#str(teachingRatings)
#create scatter plot for question 1
beautyEvalPlot <- qplot(beauty, course_eval, data=teachingRatings)
beautyEvalPlot
#histogram of beauty
beautyPlot <-qplot(beauty, data=teachingRatings)
beautyPlot
#correlation of beauty and course_eval
cor(teachingRatings$beauty, teachingRatings$course_eval)
#create a simple regression of course_eval (Y) on beauty (X)
course_evalBeautyReg <- lm(course_eval ~ beauty, data=teachingRatings)
#summarize regression
summary(course_evalBeautyReg)
confit(course_evalBeautyReg)
confit(course_evalBeautyReg)
confint(course_evalBeautyReg)
str(teachingRatings)
mean(teachingRatings$course_eval)
hist(teachingRatings$course_eval)
cov(teachingRatings$course_eval, teachingRatings$beauty)
var(teachingRatings$beauty)
mean(teachingRatings$course_eval)
mean(teachingRatings$beauty)
course_evalBeautyReg <- lm(course_eval ~ beauty, data=teachingRatings)
#summarize regression
summary(course_evalBeautyReg)
summary(teachingRatings)
length(teachingRatings)
nobs(course_evalBeautyReg)
summary(course_evalBeautyReg)
summary(teachingRatings$beauty)
sd(teachingRatings$beauty)
simulationData <- read.dta("C:\\Users\\Jackson\\Dropbox\\Grad School Work\\Econometrics 1\\Assignment 2\\simulation(3).dta")
str(simulationData)
summary(teachingRatings)
str(teachingRatings)
clear
clear()
simulationDataLM <- lm(Y~X, data=simulationData)
summary(simulationData)
summary(simulationDataLM)
cor(simulationData$E, simulationData$X)
cor(simulationData$E, simulationData$U)
cov(simulationData$E, simulationData$U)
library(ggplot2)
#library for other file formats
library(foreign)
#import data
teachingRatings <- read.dta("C:\\Users\\Jackson\\Dropbox\\Grad School Work\\Econometrics 1\\Assignment 2\\TeachingRatings.dta")
#check out data
#str(teachingRatings)
#create scatter plot for question 1
beautyEvalPlot <- qplot(beauty, course_eval, data=teachingRatings)
beautyEvalPlot
#histogram of beauty
beautyPlot <-qplot(beauty, data=teachingRatings)
beautyPlot
#correlation of beauty and course_eval
cor(teachingRatings$beauty, teachingRatings$course_eval)
#create a simple regression of course_eval (Y) on beauty (X)
course_evalBeautyReg <- lm(course_eval ~ beauty, data=teachingRatings)
#summarize regression
summary(course_evalBeautyReg)
confint(course_evalBeautyReg)
var(teachingRatings$beauty)
head(course_evalBeautyReg)
str(course_evalBeautyReg)
deviance(course_evalBeautyReg)
with(simulationData, cov(x_obx, y))
with(simulationData, cov(x_obs, y))
str(simulationData)
simulationData <- read.dta("C:\\Users\\Jackson\\Dropbox\\Grad School Work\\Econometrics 1\\Assignment 2\\simulation(3).dta")
str(simulationData)
with(simulationData, cov(x_obs, y))
with(simulationData, cov(X_OBS, y))
with(simulationData, cov(X_OBS, Y))
with(simulationData, var(X_OBS))
with(simulationData, mean(y))
with(simulationData, mean(Y))
with(simulationData, mean(X_OBS))
simulationYonXOBSLM <- lm(Y~X_OBS, data=simulationData)
summary(simulationYonXOBSLM)
simulationYOBSonX <- lm(Y_OBS~X, data=simulationData)
summary(simulationYOBSonX)
with(simulationData, mean(Y_OBS))
library(ggplot2)
#library for other file formats
library(foreign)
#import data
teachingRatings <- read.dta("C:\\Users\\Jackson\\Dropbox\\Grad School Work\\Econometrics 1\\Assignment 2\\TeachingRatings.dta")
#check out data
#str(teachingRatings)
#create scatter plot for question 1
beautyEvalPlot <- qplot(beauty, course_eval, data=teachingRatings)
beautyEvalPlot
#histogram of beauty
beautyPlot <-qplot(beauty, data=teachingRatings)
beautyPlot
#correlation of beauty and course_eval
cor(teachingRatings$beauty, teachingRatings$course_eval)
#create a simple regression of course_eval (Y) on beauty (X)
course_evalBeautyReg <- lm(course_eval ~ beauty, data=teachingRatings)
#summarize regression
summary(course_evalBeautyReg)
confint(course_evalBeautyReg)
source('~/.active-rstudio-document', echo=TRUE)
dataset[,varnames[1]], dataset[,group.name]
varnames[1]
source('~/.active-rstudio-document', echo=TRUE)
generateDataSummary <- function(dataset, varnames, group.name) {
#intiate output data frame
#set strings as factors globally, when i try and set for individual data fram its not working
options(stringsAsFactors = FALSE)
outputData <- data.frame()
for(i in 1:length(varnames)){
#for all variable names run the variable summary functions and append the results to the end of the output data frame
print(varnames[i])
outputData <- rbind(outputData, formatVariableSummary(generateVariableSummary(dataset[,varnames[i]], dataset[,group.name])))
}
#set rownames of data frame to variable names
rownames(outputData) <- varnames
#create character vector to be used for column headings
colnames <- c("Missing")
#ensure factor levels from group.names are passed as characters
factors <- as.character(unique(dataset[,group.name]))
#push factor levels into column heading vector
for(i in 1:length(factors)){
colnames[i+1] <- as.character(factors[i])
}
colnames[length(colnames)+1] <- c("P-Value")
#set column headings to colnames
colnames(outputData) <- colnames
#reset strings as factors to true
options(stringsAsFactors = TRUE)
return(outputData)
}
str(dataset)
generateDataSummary <- function(dataset, varnames, group.name) {
#intiate output data frame
#set strings as factors globally, when i try and set for individual data fram its not working
options(stringsAsFactors = FALSE)
outputData <- data.frame()
for(i in 1:length(varnames)){
#for all variable names run the variable summary functions and append the results to the end of the output data frame
print(varnames[i])
outputData <- rbind(outputData, formatVariableSummary(generateVariableSummary(dataset[,varnames[i]], dataset[,group.name])))
}
#set rownames of data frame to variable names
rownames(outputData) <- varnames
#create character vector to be used for column headings
colnames <- c("Missing")
#ensure factor levels from group.names are passed as characters
factors <- as.character(unique(dataset[,group.name]))
#push factor levels into column heading vector
for(i in 1:length(factors)){
colnames[i+1] <- as.character(factors[i])
}
colnames[length(colnames)+1] <- c("P-Value")
#set column headings to colnames
colnames(outputData) <- colnames
#reset strings as factors to true
options(stringsAsFactors = TRUE)
return(outputData)
str(dataset)
}
str(income)
head(income)
dataset <-income
dataset$age
clear
clear()
generateDataSummary <- function(dataset, varnames, group.name) {
#intiate output data frame
#set strings as factors globally, when i try and set for individual data fram its not working
options(stringsAsFactors = FALSE)
outputData <- data.frame()
for(i in 1:length(varnames)){
#for all variable names run the variable summary functions and append the results to the end of the output data frame
print(varnames[i])
outputData <- rbind(outputData, formatVariableSummary(generateVariableSummary(dataset$varnames[i], dataset[,group.name])))
}
#set rownames of data frame to variable names
rownames(outputData) <- varnames
#create character vector to be used for column headings
colnames <- c("Missing")
#ensure factor levels from group.names are passed as characters
factors <- as.character(unique(dataset[,group.name]))
#push factor levels into column heading vector
for(i in 1:length(factors)){
colnames[i+1] <- as.character(factors[i])
}
colnames[length(colnames)+1] <- c("P-Value")
#set column headings to colnames
colnames(outputData) <- colnames
#reset strings as factors to true
options(stringsAsFactors = TRUE)
return(outputData)
}
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
str(income)
source('~/.active-rstudio-document', echo=TRUE)
restaurantGrades <- read.xlsx("C:\\Users\\Jackson\Dropbox\\Grad School Work\\BIDM\\Final Project\\ZipCodeDemographicData_NoBlankorNegativeScores_FINAL.xlsx")
restaurantGrades <- read.xlsx("C:\\Users\\Jackson\\Dropbox\\Grad School Work\\BIDM\\Final Project\\ZipCodeDemographicData_NoBlankorNegativeScores_FINAL.xlsx")
restaurantGrades <- read.csv("C:\\Users\\Jackson\\Dropbox\\Grad School Work\\BIDM\\Final Project\\ZipCodeDemographicData_NoBlankorNegativeScores_FINAL.csv")
install.packages("ggmap")
install.packages(c('lubridate', 'gam'))
install.packages(c('broom', 'hexbin', 'mclust'))
set.seed(1)
library(mclust) #Mclust
library(ggplot2)
library(reshape2)
library(plyr)
library(ggmap) # maps and houston crime dataset
library(lubridate) #date-time stuff
library(splines)
library(gam)
library(hexbin) #geom_hexbin
library(broom)
import.csv <- function(filename) {
return(read.csv(filename, sep = ",", header = TRUE))
}
nypd_data <- import.csv('C:\\Users\\Jackson\\Dropbox\\Grad School Work\\Data Warehousing\\NYPD_Motor_Vehicle_Collisions.csv')
nypd_data$LOCATION <- NULL
nypd_data$BOROUGH[nypd_data$BOROUGH=='']<-NA
nypd_data$ZIP.CODE[nypd_data$ZIP.CODE=='']<-NA
nypd_data$LATITUDE[nypd_data$LATITUDE=='']<-NA
nypd_data$LONGITUDE[nypd_data$LONGITUDE=='']<-NA
nypd_data$ON.STREET.NAME[nypd_data$ON.STREET.NAME=='']<-NA
nypd_data$CROSS.STREET.NAME[nypd_data$CROSS.STREET.NAME=='']<-NA
nypd_data$OFF.STREET.NAME[nypd_data$OFF.STREET.NAME=='']<-NA
nypd_data$CONTRIBUTING.FACTOR.VEHICLE.1[nypd_data$CONTRIBUTING.FACTOR.VEHICLE.1=='']<-NA
nypd_data$CONTRIBUTING.FACTOR.VEHICLE.2[nypd_data$CONTRIBUTING.FACTOR.VEHICLE.2=='']<-NA
nypd_data$CONTRIBUTING.FACTOR.VEHICLE.3[nypd_data$CONTRIBUTING.FACTOR.VEHICLE.3=='']<-NA
nypd_data$CONTRIBUTING.FACTOR.VEHICLE.4[nypd_data$CONTRIBUTING.FACTOR.VEHICLE.4=='']<-NA
nypd_data$CONTRIBUTING.FACTOR.VEHICLE.5[nypd_data$CONTRIBUTING.FACTOR.VEHICLE.5=='']<-NA
nypd_data$VEHICLE.TYPE.CODE.1[nypd_data$VEHICLE.TYPE.CODE.1=='']<-NA
nypd_data$VEHICLE.TYPE.CODE.2[nypd_data$VEHICLE.TYPE.CODE.2=='']<-NA
nypd_data$VEHICLE.TYPE.CODE.3[nypd_data$VEHICLE.TYPE.CODE.3=='']<-NA
nypd_data$VEHICLE.TYPE.CODE.4[nypd_data$VEHICLE.TYPE.CODE.4=='']<-NA
nypd_data$VEHICLE.TYPE.CODE.5[nypd_data$VEHICLE.TYPE.CODE.5=='']<-NA
nypd_data$DATE<-mdy(nypd_data$DATE)
hour_minute <- strsplit(as.character(nypd_data$TIME), ":")
df <- ldply(hour_minute)
nypd_data$HOUR<-df[,1]
nypd_data$MINUTE<-df[,2]
newyork.ggmap = get_map(location = 'new york', zoom=10)
ggmap(newyork.ggmap)
ggmap(newyork.ggmap) + geom_point(data = nypd_data, mapping=aes(x=LONGITUDE, y=LATITUDE), size=1, alpha=.6)
ggmap(newyork.ggmap) + stat_binhex(data = nypd_data, mapping=aes(x=LONGITUDE, y=LATITUDE), alpha=.6)
ggmap(newyork.ggmap) + stat_density2d(data = nypd_data, mapping=aes(x=LONGITUDE, y=LATITUDE, fill = ..level.., alpha = ..level..), geom='polygon', bins=12)  + scale_alpha(guide=FALSE)
count.day = ddply(nypd_data, "DATE", summarize, count = length(DATE))
ggplot(data = count.day, mapping=aes(x=DATE, y=count)) + geom_point() + geom_smooth(method='lm', formula = y~ns(x, df=6))
set.seed(1)
library(mclust) #Mclust
library(reshape2)
library(ggplot2)
library(plyr)
library(ggmap) # maps and houston crime dataset
library(lubridate) #date-time stuff
library(splines)
library(gam)
library(hexbin) #geom_hexbin
library(broom)
import.csv <- function(filename) {
return(read.csv(filename, sep = ",", header = TRUE))
}
manhattan.ggmap = get_map(location = 'manhattan', zoom=12)
ggmap(manhattan.ggmap) + stat_density2d(data = nypd_data[nypd_data$BOROUGH=="MANHATTAN",], mapping=aes(x=LONGITUDE, y=LATITUDE, fill = ..level.., alpha = ..level..), geom='polygon', bins=12)  + scale_alpha(guide=FALSE)
nypd_data <- import.csv('C:\\Users\\Jackson\\Dropbox\\Grad School Work\\Data Warehousing\\NYPD_Motor_Vehicle_Collisions.csv')
nypd_data$LOCATION <- NULL
nypd_data$BOROUGH[nypd_data$BOROUGH=='']<-NA
nypd_data$ZIP.CODE[nypd_data$ZIP.CODE=='']<-NA
nypd_data$LATITUDE[nypd_data$LATITUDE=='']<-NA
nypd_data$LONGITUDE[nypd_data$LONGITUDE=='']<-NA
nypd_data$ON.STREET.NAME[nypd_data$ON.STREET.NAME=='']<-NA
nypd_data$CROSS.STREET.NAME[nypd_data$CROSS.STREET.NAME=='']<-NA
nypd_data$OFF.STREET.NAME[nypd_data$OFF.STREET.NAME=='']<-NA
nypd_data$CONTRIBUTING.FACTOR.VEHICLE.1[nypd_data$CONTRIBUTING.FACTOR.VEHICLE.1=='']<-NA
nypd_data$CONTRIBUTING.FACTOR.VEHICLE.2[nypd_data$CONTRIBUTING.FACTOR.VEHICLE.2=='']<-NA
nypd_data$CONTRIBUTING.FACTOR.VEHICLE.3[nypd_data$CONTRIBUTING.FACTOR.VEHICLE.3=='']<-NA
nypd_data$CONTRIBUTING.FACTOR.VEHICLE.4[nypd_data$CONTRIBUTING.FACTOR.VEHICLE.4=='']<-NA
nypd_data$CONTRIBUTING.FACTOR.VEHICLE.5[nypd_data$CONTRIBUTING.FACTOR.VEHICLE.5=='']<-NA
nypd_data$VEHICLE.TYPE.CODE.1[nypd_data$VEHICLE.TYPE.CODE.1=='']<-NA
nypd_data$VEHICLE.TYPE.CODE.2[nypd_data$VEHICLE.TYPE.CODE.2=='']<-NA
nypd_data$VEHICLE.TYPE.CODE.3[nypd_data$VEHICLE.TYPE.CODE.3=='']<-NA
nypd_data$VEHICLE.TYPE.CODE.4[nypd_data$VEHICLE.TYPE.CODE.4=='']<-NA
nypd_data$VEHICLE.TYPE.CODE.5[nypd_data$VEHICLE.TYPE.CODE.5=='']<-NA
nypd_data$DATE<-mdy(nypd_data$DATE)
hour_minute <- strsplit(as.character(nypd_data$TIME), ":")
df <- ldply(hour_minute)
nypd_data$HOUR<-df[,1]
nypd_data$MINUTE<-df[,2]
newyork.ggmap = get_map(location = 'new york', zoom=10)
ggmap(newyork.ggmap)
ggmap(newyork.ggmap) + geom_point(data = nypd_data, mapping=aes(x=LONGITUDE, y=LATITUDE), size=1, alpha=.6)
ggmap(newyork.ggmap) + stat_binhex(data = nypd_data, mapping=aes(x=LONGITUDE, y=LATITUDE), alpha=.6)
ggmap(newyork.ggmap) + stat_density2d(data = nypd_data, mapping=aes(x=LONGITUDE, y=LATITUDE, fill = ..level.., alpha = ..level..), geom='polygon', bins=12)  + scale_alpha(guide=FALSE)
install.packages("gplots", "FNN")
require(graphics)
# Let's use some example data from the R libraries: USArrests
# Have a quick look at the data
head(USArrests)
summary(USArrests)
# You should see that the measured variables are on
# different scales: Assault varies from 45 to 337, but
# all other variables only from 1 to 90.
# If we use raw values, it's possible that the absolutely,
# but not proportionately greater variance of Assault
# might affect our analysis.
# You should scale data whenever your variables differ
# by orders of magnitude, as they do here.
# Transcription data usually varies over orders of
# magnitude, so scaling is appropriate.
# We'll run PCA with prcomp (SVD-based), with and without
# scaling to unit variance
unscaled = prcomp(USArrests)
scaled = prcomp(USArrests, scale = TRUE)
# Let's plot the results as a screeplot
par(mfrow=c(2,1))
plot(unscaled)
plot(scaled)
screeplot(unscaled)
screeplot(scaled)
head(USArrests)
summary(USArrests)
unscaled = prcomp(USArrests)
scaled = prcomp(USArrests, scale = TRUE)
# Let's plot the results as a screeplot
par(mfrow=c(2,1))
screeplot(unscaled)
screeplot(unscaled, type = 'lines')
install.packages("ROCR")
install.packages(c("BH", "broom", "caret", "colorspace", "digest", "formatR", "gam", "GGally", "ggmap", "ggplot2", "glmnet", "hexbin", "highr", "htmltools", "httpuv", "knitr", "lattice", "lubridate", "manipulate", "mapproj", "maps", "markdown", "Matrix", "mclust", "mime", "mnormt", "multcomp", "mvtnorm", "pbkrtest", "psych", "R6", "rattle", "RColorBrewer", "Rcpp", "RcppEigen", "reshape2", "scales", "shiny", "stringi", "stringr", "tidyr", "xtable"))
install.packages(c("BH", "broom", "caret", "colorspace", "digest",
install.packages(c("BH", "broom", "caret", "colorspace", "digest", "formatR", "gam", "GGally", "ggmap", "ggplot2", "glmnet", "hexbin", "highr", "htmltools", "httpuv", "knitr", "lattice", "lubridate", "manipulate", "mapproj", "maps", "markdown", "Matrix", "mclust", "mime", "mnormt", "multcomp", "mvtnorm", "pbkrtest", "psych", "R6", "rattle", "RColorBrewer", "Rcpp", "RcppEigen", "reshape2", "scales", "shiny", "stringi", "stringr", "tidyr", "xtable"))
install.packages(c("BH", "broom", "caret", "colorspace", "digest",
install.packages(c("BH", "broom", "caret", "colorspace", "digest", "formatR", "gam", "GGally", "ggmap", "ggplot2", "glmnet", "hexbin", "highr", "htmltools", "httpuv", "knitr", "lattice", "lubridate", "manipulate", "mapproj", "maps", "markdown", "Matrix", "mclust", "mime", "mnormt", "multcomp", "mvtnorm", "pbkrtest", "psych", "R6", "rattle", "RColorBrewer", "Rcpp", "RcppEigen", "reshape2", "scales", "shiny", "stringi", "stringr", "tidyr", "xtable"))
sessionInfo()
library(ggplot2)
library(ggplot2)
sessionInfo()
install.packages("ggplot2")
library(plyr)
library(ggplot2)
library(ggmap)
library(knitr)
library(zoo)
library(lubridate)
setwd("C:/Users/Jackson/Dropbox/Grad_School_Work/R_Practice/Pitt_Bike")
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
library(plyr)
library(ggplot2)
library(ggmap)
library(knitr)
library(lubridate)
#read in data
trips <- read.csv("trips_Q3_2015.csv", na.strings = "", stringsAsFactors = FALSE)
stations <- read.csv("Stations_2015.csv", na.strings = "", stringsAsFactors = FALSE)
#convert times into lubridate objs
trips$LubStartTime <- force_tz(mdy_hm(trips$StartTime), tzone = "America/New_York")
trips$LubEndTime <- force_tz(mdy_hm(trips$StopTime), tzone = "America/New_York")
###thought durations were all messed up but they weren't
###can keep as lubridate objecst to work with
trips$duration_min <- trips$TripDuration/60
# trips$interval <- interval(trips$LubStartTime, trips$LubEndTime, tzone = "America/New_York")
# trips$Lub_duration <- as.duration(trips$interval)/dminutes(1)
trips$Lub_start_day <- wday(trips$LubStartTime, label = TRUE, abbr = TRUE)
#use format to pull out just the date info
trips$LubStartDate <- format(trips$LubStartTime, "%Y/%m/%d")
trips$LubEndDate <- format(trips$LubEndTime, "%Y/%m/%d")
